import os
import logging
import time
from dotenv import load_dotenv
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
import google.generativeai as genai

# 設定読み込み
from agents import AGENTS_CONFIG, AGENT_PROFILES, BRAINSTORMING_CHANNEL_ID, DEFAULT_PROMPT

# 環境変数の読み込み
load_dotenv()

# ログ設定
logging.basicConfig(level=logging.INFO)

# 初期化
app = App(token=os.environ["SLACK_BOT_TOKEN"])
genai.configure(api_key=os.environ["GEMINI_API_KEY"])

# Bot自身のID
BOT_ID = app.client.auth_test()["user_id"]

def get_thread_history(channel_id, thread_ts):
    """
    Slackのスレッド履歴を取得し、Gemini用の形式に変換する関数
    """
    try:
        # スレッドのメッセージを取得
        result = app.client.conversations_replies(
            channel=channel_id,
            ts=thread_ts
        )
        messages = result.get("messages", [])
        
        gemini_history = []
        
        for msg in messages:
            text = msg.get("text", "")
            user = msg.get("user")
            
            # Bot自身の発言は 'model'、ユーザーの発言は 'user' とする
            role = "model" if user == BOT_ID else "user"
            
            # Geminiの履歴フォーマットに追加
            gemini_history.append({
                "role": role,
                "parts": [text]
            })
            
        # 最新のメッセージ（今回の入力）は履歴から除外して別途扱うこともできるが、
        # ここでは履歴全体を渡して、最後の発言に対して応答させる形をとる
        return gemini_history
        
    except Exception as e:
        logging.error(f"Error fetching history: {e}")
        return []

def call_gemini(system_prompt, user_prompt):
    """
    Gemini APIを呼び出して応答を取得する関数
    """
    try:
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            system_instruction=system_prompt
        )
        response = model.generate_content(user_prompt)
        return response.text
    except Exception as e:
        logging.error(f"Gemini API Error: {e}")
        return f"エラーが発生しました: {str(e)}"

def post_as_agent(channel_id, thread_ts, text, role_key):
    """
    指定したエージェントの顔と名前でSlackに投稿する関数
    """
    profile = AGENT_PROFILES[role_key]
    app.client.chat_postMessage(
        channel=channel_id,
        thread_ts=thread_ts,
        text=text,
        username=profile["name"],   # 名前を偽装
        icon_emoji=profile["icon"]  # アイコンを偽装
    )

def run_brainstorming_session(channel_id, thread_ts, user_topic):
    """
    【ここが心臓部】自律会議のシナリオ
    """
    
    # --- ターン1: 企画担当が案を出す ---
    prompt_1 = f"テーマ「{user_topic}」で、YouTube企画案を1つ出してください。視聴維持率を意識したフックも書いてください。"
    # Gemini呼び出し(企画担当の人格で)
    planner_res = call_gemini(AGENT_PROFILES["Planner"]["prompt"], prompt_1)
    
    # Slackに投稿
    post_as_agent(channel_id, thread_ts, planner_res, "Planner")
    time.sleep(2) # 人間味を出すウェイト

    # --- ターン2: 鬼Dがダメ出しする ---
    # 直前の企画案をコンテキストに含める
    prompt_2 = f"以下の企画案に対して、再生数が伸びないリスクを厳しく指摘してください。\n\n企画案：{planner_res}"
    director_res = call_gemini(AGENT_PROFILES["Director"]["prompt"], prompt_2)
    
    post_as_agent(channel_id, thread_ts, director_res, "Director")
    time.sleep(2)

    # --- ターン3: 企画担当が修正案を出す(ブラッシュアップ) ---
    prompt_3 = f"ディレクターから以下の指摘がありました。これを踏まえて、企画を改善した「最終案」を出してください。\n\n指摘：{director_res}"
    final_res = call_gemini(AGENT_PROFILES["Planner"]["prompt"], prompt_3)
    
    post_as_agent(channel_id, thread_ts, f"ぐぬぬ...分かりました！これでどうですか！？\n\n{final_res}", "Planner")

    # --- 終了 ---
    app.client.chat_postMessage(
        channel=channel_id,
        thread_ts=thread_ts,
        text="会議終了。この案で進めますか？"
    )

@app.event("app_mention")
def handle_mention(event, say):
    """
    メンションされた時の処理(メインロジック)
    """
    channel_id = event["channel"]
    thread_ts = event.get("thread_ts", event["ts"]) # スレッド内ならそのID、新規なら自分のID
    user_text = event["text"]

    logging.info(f"Received message in channel: {channel_id}")

    # 特殊コマンド: ブレインストーミングセッションを開始
    if "会議開始" in user_text or "ブレスト" in user_text:
        # テーマを抽出(簡易実装)
        topic = user_text.replace("<@" + BOT_ID + ">", "").replace("会議開始", "").replace("ブレスト", "").strip()
        if not topic:
            topic = "面白いYouTube企画"
        
        say(text=f"了解しました！テーマ「{topic}」で会議を開始します...", thread_ts=thread_ts)
        run_brainstorming_session(channel_id, thread_ts, topic)
        return

    # 1. Routing: チャンネルIDに基づいてエージェント人格を選択
    agent_config = AGENTS_CONFIG.get(channel_id)
    
    if agent_config:
        system_instruction = agent_config["system_prompt"]
        role_name = agent_config["role"]
        logging.info(f"Agent selected: {role_name}")
    else:
        system_instruction = DEFAULT_PROMPT
        logging.info("Agent selected: Default")

    # 2. Context Fetching: 会話履歴の取得
    # Geminiに渡すための履歴リストを作成
    history = get_thread_history(channel_id, thread_ts)

    # 3. Generation: Gemini API呼び出し
    try:
        # システムプロンプトを設定してモデルを初期化
        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash", # または "gemini-1.5-pro"
            system_instruction=system_instruction
        )

        # チャットセッションを開始(履歴付き)
        # historyの最後がユーザーの入力になっているはずなので、それをトリガーにする
        # ただし、APIの仕様上、start_chatに渡すhistoryは「最後の1件(今回の問い)」を含まない過去ログが望ましい場合がある
        # ここではシンプルに `generate_content` に履歴リスト全体を渡すアプローチをとるか、
        # `start_chat` を使う。今回は文脈維持のため `start_chat` を採用。
        
        # historyの末尾(今回のユーザー発言)を取り出す
        current_message = history[-1]['parts'][0]
        past_history = history[:-1] if len(history) > 1 else []

        chat = model.start_chat(history=past_history)
        response = chat.send_message(current_message)
        
        reply_text = response.text

    except Exception as e:
        reply_text = f"申し訳ありません。思考回路にエラーが発生しました。\nError: {str(e)}"
        logging.error(f"Gemini API Error: {e}")

    # 4. Output: 返信
    say(text=reply_text, thread_ts=thread_ts)

if __name__ == "__main__":
    handler = SocketModeHandler(app, os.environ["SLACK_APP_TOKEN"])
    handler.start()